{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQAqOS2xwiYG"
   },
   "source": [
    "Mount Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 7645,
     "status": "ok",
     "timestamp": 1731235830070,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "fmTH9UkeqdYf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# import re\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1731235836244,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "x0KHo8w9yqbY"
   },
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, n_x, n_y, seed=1):\n",
    "        self.n_x = n_x\n",
    "        self.n_y = n_y\n",
    "        self.seed = seed\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        self.n_x -- size of the input layer\n",
    "        self.n_y -- size of the output layer\n",
    "        self.parameters -- python dictionary containing your parameters:\n",
    "                           W -- weight matrix of shape (n_x, n_y)\n",
    "                           b -- bias vector of shape (1, n_y)\n",
    "        \"\"\"\n",
    "        sd = np.sqrt(6.0 / (self.n_x + self.n_y))\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.random.uniform(-sd, sd, (self.n_y, self.n_x)).T      # the transpose here is just for the code to be compatible with the old codes\n",
    "        b = np.zeros((1, self.n_y))\n",
    "\n",
    "        assert(W.shape == (self.n_x, self.n_y))\n",
    "        assert(b.shape == (1, self.n_y))\n",
    "\n",
    "        self.parameters = {\"W\": W, \"b\": b}\n",
    "\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "        Arguments:\n",
    "        A -- activations from previous layer (or input data) with the shape (n, f^[l-1])\n",
    "        self.cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "\n",
    "        Returns:\n",
    "        Z -- the input of the activation function, also called pre-activation parameter with the shape (n, f^[l])\n",
    "        \"\"\"\n",
    "\n",
    "        # GRADED FUNCTION: linear_forward\n",
    "        ### START CODE HERE ###\n",
    "        w = self.parameters[\"W\"]\n",
    "        b = self.parameters[\"b\"]\n",
    "        Z = np.dot(A, w) + b\n",
    "        self.cache = (A, w, b)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        assert(Z.shape == (A.shape[0], self.parameters[\"W\"].shape[1]))\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "        Arguments:\n",
    "        dZ -- Gradient of the loss with respect to the linear output (of current layer l), same shape as Z\n",
    "        self.cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "        self.dW -- Gradient of the loss with respect to W (current layer l), same shape as W\n",
    "        self.db -- Gradient of the loss with respect to b (current layer l), same shape as b\n",
    "\n",
    "        Returns:\n",
    "        dA_prev -- Gradient of the loss with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "\n",
    "        \"\"\"\n",
    "        A_prev, W, b = self.cache\n",
    "        m = A_prev.shape[0]\n",
    "\n",
    "        # GRADED FUNCTION: linear_backward\n",
    "        ### START CODE HERE ###\n",
    "        self.dW = np.dot(A_prev.T, dZ) / m\n",
    "        self.db = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "        dA_prev = np.dot(dZ, W.T)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        assert (dA_prev.shape == A_prev.shape)\n",
    "        assert (self.dW.shape == self.parameters[\"W\"].shape)\n",
    "        assert (self.db.shape == self.parameters[\"b\"].shape)\n",
    "\n",
    "        return dA_prev\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update parameters using gradient descent\n",
    "\n",
    "        Arguments:\n",
    "        learning rate -- step size\n",
    "        \"\"\"\n",
    "\n",
    "        # GRADED FUNCTION: linear_update_parameters\n",
    "        ### START CODE HERE ###\n",
    "        self.parameters[\"W\"] = self.parameters[\"W\"] - learning_rate * self.dW\n",
    "        self.parameters[\"b\"] = self.parameters[\"b\"] - learning_rate * self.db\n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1731235843574,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "Nnuv8MmebMgg"
   },
   "outputs": [],
   "source": [
    "class Activation():\n",
    "    def __init__(self, activation_function, loss_function):\n",
    "        self.activation_function = activation_function\n",
    "        self.loss_function = loss_function\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, Z):\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            \"\"\"\n",
    "            Implements the sigmoid activation in numpy\n",
    "\n",
    "            Arguments:\n",
    "            Z -- numpy array of any shape\n",
    "            self.cache -- stores Z as well, useful during backpropagation\n",
    "\n",
    "            Returns:\n",
    "            A -- output of sigmoid(z), same shape as Z\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: sigmoid_forward\n",
    "            ### START CODE HERE ###\n",
    "            A = 1 / (1 + np.exp(-Z))\n",
    "            self.cache = Z\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            return A\n",
    "        elif self.activation_function == \"relu\":\n",
    "            \"\"\"\n",
    "            Implement the RELU function in numpy\n",
    "            Arguments:\n",
    "            Z -- numpy array of any shape\n",
    "            self.cache -- stores Z as well, useful during backpropagation\n",
    "            Returns:\n",
    "            A -- output of relu(z), same shape as Z\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: relu_forward\n",
    "            ### START CODE HERE ###\n",
    "            A = np.maximum(0, Z)\n",
    "            self.cache = Z\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            assert(A.shape == Z.shape)\n",
    "\n",
    "            return A\n",
    "        elif self.activation_function == \"softmax\":\n",
    "            \"\"\"\n",
    "            Implements the softmax activation in numpy\n",
    "\n",
    "            Arguments:\n",
    "            Z -- np.array with shape (n, C)\n",
    "            self.cache -- stores Z as well, useful during backpropagation\n",
    "\n",
    "            Returns:\n",
    "            A -- output of softmax(z), same shape as Z\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: softmax_forward\n",
    "            ### START CODE HERE ###\n",
    "            eZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "            A = eZ / np.sum(eZ, axis=1, keepdims=True)\n",
    "            self.cache = Z\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            return A\n",
    "        elif self.activation_function == \"linear\":\n",
    "            \"\"\"\n",
    "            Linear activation (returns Z directly).\n",
    "            \"\"\"\n",
    "            self.cache = Z.copy()\n",
    "            return Z\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {self.activation_function}\")\n",
    "\n",
    "\n",
    "    def backward(self, dA=None, Y=None):\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            \"\"\"\n",
    "            Implement the backward propagation for a single SIGMOID unit.\n",
    "            Arguments:\n",
    "            dA -- post-activation gradient, of any shape\n",
    "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "            Returns:\n",
    "            dZ -- Gradient of the loss with respect to Z\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: sigmoid_backward\n",
    "            ### START CODE HERE ###\n",
    "            Z = self.cache\n",
    "            sigmoid = 1 / (1 + np.exp(-Z))\n",
    "            dZ = dA * sigmoid * (1 - sigmoid)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            assert (dZ.shape == Z.shape)\n",
    "\n",
    "            return dZ\n",
    "\n",
    "        elif self.activation_function == \"relu\":\n",
    "            \"\"\"\n",
    "            Implement the backward propagation for a single RELU unit.\n",
    "            Arguments:\n",
    "            dA -- post-activation gradient, of any shape\n",
    "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "            Returns:\n",
    "            dZ -- Gradient of the loss with respect to Z\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: relu_backward\n",
    "            ### START CODE HERE ###\n",
    "            Z = self.cache\n",
    "            dZ = np.array(dA, copy=True)\n",
    "            dZ[Z <= 0] = 0\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            assert (dZ.shape == Z.shape)\n",
    "\n",
    "            return dZ\n",
    "\n",
    "        elif self.activation_function == \"softmax\":\n",
    "            \"\"\"\n",
    "            Implement the backward propagation for a [SOFTMAX->CCE LOSS] unit.\n",
    "            Arguments:\n",
    "            Y -- true \"label\" vector (one hot vector, for example: [1,0,0] represents rock, [0,1,0] represents paper, [0,0,1] represents scissors\n",
    "                                      in a Rock-Paper-Scissors, shape: (n, C)\n",
    "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "            Returns:\n",
    "            dZ -- Gradient of the cost with respect to Z\n",
    "            \"\"\"\n",
    "\n",
    "            # GRADED FUNCTION: softmax_backward\n",
    "            ### START CODE HERE ###\n",
    "            Z = self.cache\n",
    "            softmax = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "            softmax = softmax / np.sum(softmax, axis=1, keepdims=True)\n",
    "            dZ = softmax - Y\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            assert (dZ.shape == self.cache.shape)\n",
    "\n",
    "            return dZ\n",
    "\n",
    "        elif self.activation_function == \"linear\":\n",
    "            \"\"\"\n",
    "            Backward propagation for linear activation.\n",
    "            \"\"\"\n",
    "            return dA\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {self.activation_function}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1731235849661,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "0JGMzfIDCSVz"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, units, activation_functions, loss_function):\n",
    "        self.units = units\n",
    "        self.activation_functions = activation_functions\n",
    "        self.loss_function = loss_function\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize layers of the neural network\n",
    "\n",
    "        Arguments:\n",
    "            self.units -- array defining network structure (e.g., [4,4,1]):\n",
    "                - Input layer: 4 nodes\n",
    "                - Hidden layer: 4 nodes\n",
    "                - Output layer: 1 node\n",
    "            self.activation_functions -- activation function for each layer (e.g., [\"relu\",\"sigmoid\"]):\n",
    "                - First layer uses ReLU\n",
    "                - Second layer uses Sigmoid\n",
    "            self.loss_function -- loss function type: \"cross_entropy\" or \"mse\"\n",
    "        \"\"\"\n",
    "        self.linear = []        # Store all Dense layers (weights & biases)\n",
    "        self.activation = []    # Store all activation function layers\n",
    "\n",
    "        for i in range(len(self.units)-1):\n",
    "            dense = Dense(self.units[i], self.units[i+1], i)\n",
    "            self.linear.append(dense)\n",
    "\n",
    "        for i in range(len(self.activation_functions)):\n",
    "            self.activation.append(Activation(self.activation_functions[i], self.loss_function))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward propagation through the network\n",
    "\n",
    "        Arguments:\n",
    "        X -- input data: shape (n, f)\n",
    "        Returns:\n",
    "        A -- model output:\n",
    "            - For binary classification: probability (0-1)\n",
    "            - For multi-class: probability distribution across classes\n",
    "            - For regression: predicted values\n",
    "        \"\"\"\n",
    "        A = X\n",
    "\n",
    "        # GRADED FUNCTION: model_forward\n",
    "        ### START CODE HERE ###\n",
    "        for i in range(len(self.linear)):\n",
    "          Z = self.linear[i].forward(A) # forward\n",
    "          A = self.activation[i].forward(Z) # activation\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, AL=None, Y=None):\n",
    "        \"\"\"\n",
    "        Backward propagation to compute gradients\n",
    "\n",
    "        Arguments:\n",
    "            AL -- model output from forward propagation:\n",
    "                - For binary: probability (n,1)\n",
    "                - For multi-class: probabilities (n,C)\n",
    "            Y -- true labels:\n",
    "                - For binary: 0/1 labels (n,1)\n",
    "                - For multi-class: one-hot vectors (n,C)\n",
    "                - For regression: true values (n,1)\n",
    "\n",
    "        Returns:\n",
    "            dA_prev -- gradients for previous layer's activation\n",
    "        \"\"\"\n",
    "\n",
    "        L = len(self.linear)\n",
    "        C = Y.shape[1]\n",
    "\n",
    "        # assertions\n",
    "        warning = 'Warning: only the following 3 combinations are allowed! \\n \\\n",
    "                    1. binary classification: sigmoid + cross_entropy \\n \\\n",
    "                    2. multi-class classification: softmax + cross_entropy \\n \\\n",
    "                    3. regression: linear + mse'\n",
    "        assert self.loss_function in [\"cross_entropy\", \"mse\"], \"you're using undefined loss function!\"\n",
    "        if self.loss_function == \"cross_entropy\":\n",
    "            if Y.shape[1] == 1:  # binary classification\n",
    "                assert self.activation_functions[-1] == 'sigmoid', warning\n",
    "            else:  # multi-class classification\n",
    "                assert self.activation_functions[-1] == 'softmax', warning\n",
    "                assert self.units[-1] == Y.shape[1], f\"you should set last dim to {Y.shape[1]}(the number of classes) in multi-class classification!\"\n",
    "        elif self.loss_function == \"mse\":\n",
    "            assert self.activation_functions[-1] == 'linear', warning\n",
    "            assert self.units[-1] == Y.shape[1], \"output dimension mismatch for regression!\"\n",
    "\n",
    "        # GRADED FUNCTION: model_backward\n",
    "        ### START CODE HERE ###\n",
    "        dAL = 0.0\n",
    "        # Initializing the backpropagation\n",
    "        if self.loss_function == \"cross_entropy\":\n",
    "          dAL = (-1 * (Y / (AL + 0.00001))) + ((1 - Y) / (1 - AL + 0.00001))\n",
    "        elif self.loss_function == \"mse\":\n",
    "          dAL = AL - Y\n",
    "\n",
    "        if self.activation_functions[-1] == \"linear\":\n",
    "          # Lth layer (LINEAR) gradients. Inputs: \"dAL\". Outputs: \"dA_prev\"\n",
    "          dZ = dAL\n",
    "          dA_prev = self.linear[-1].backward(dZ)\n",
    "\n",
    "        elif self.activation_functions[-1] == \"sigmoid\":\n",
    "          # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL\". Outputs: \"dA_prev\"\n",
    "          dZ = self.activation[-1].backward(dAL)\n",
    "          dA_prev = self.linear[-1].backward(dZ)\n",
    "\n",
    "        elif self.activation_functions[-1] == \"softmax\":\n",
    "          dZ = self.activation[-1].backward(Y=Y)\n",
    "          dA_prev = self.linear[-1].backward(dZ)\n",
    "\n",
    "        # Loop from l=L-2 to l=0\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"dA_prev\". Outputs: \"dA_prev\"\n",
    "        for l in reversed(range(L - 1)):\n",
    "          dZ = self.activation[l].backward(dA_prev)\n",
    "          dA_prev = self.linear[l].backward(dZ)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return dA_prev\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        learning_rate -- step size\n",
    "        \"\"\"\n",
    "\n",
    "        L = len(self.linear)\n",
    "\n",
    "        # GRADED FUNCTION: model_update_parameters\n",
    "        ### START CODE HERE ###\n",
    "        for l in self.linear:\n",
    "          l.update(learning_rate)\n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1731235865258,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "6RHLNGsepygt"
   },
   "outputs": [],
   "source": [
    "def compute_MSE_loss(AL, Y):\n",
    "    # 檢查 AL 和 Y 是否有 NaN 或無效值\n",
    "    if np.any(np.isnan(AL)) or np.any(np.isnan(Y)):\n",
    "        raise ValueError(\"AL or Y contains NaN values!\")\n",
    "    if np.any(np.isinf(AL)) or np.any(np.isinf(Y)):\n",
    "        raise ValueError(\"AL or Y contains Inf values!\")\n",
    "    \n",
    "    # 防止 m 為 0\n",
    "    m = Y.shape[0]\n",
    "    if m == 0:\n",
    "        raise ValueError(\"Number of samples (m) is zero, cannot compute loss.\")\n",
    "    \n",
    "    # 計算 MSE loss\n",
    "    loss = (1 / m) * np.sum(np.square(AL - Y))\n",
    "    return loss\n",
    "\n",
    "# compute_MSE_loss (MSE)\n",
    "def compute_MSE_loss(AL, Y):\n",
    "    m = Y.shape[0]\n",
    "    loss = (1/m) * np.sum(np.square(AL - Y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1731235865258,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "woCqucFUYXe6"
   },
   "outputs": [],
   "source": [
    "# def predict(x, y_true, model):\n",
    "#     \"\"\"\n",
    "#     This function is used to predict the results of a  L-layer neural network.\n",
    "\n",
    "#     Arguments:\n",
    "#     x -- data set of examples you would like to label\n",
    "#     model -- trained model\n",
    "\n",
    "#     Returns:\n",
    "#     y_pred -- predictions for the given dataset X\n",
    "#     \"\"\"\n",
    "\n",
    "#     n = x.shape[0]\n",
    "\n",
    "#     # Forward propagation\n",
    "#     y_pred = model.forward(x)\n",
    "\n",
    "#     # this transform the output and label of binary classification when using sigmoid + cross entropy for evaluation\n",
    "#     # eg. y_pred: [[0.8], [0.2], [0.1]] -> [[0.2, 0.8], [0.8, 0.2], [0.9, 0.1]]\n",
    "#     # eg. y_true: [[1], [0], [0]] -> [[0, 1], [1, 0], [1, 0]]\n",
    "#     if y_pred.shape[-1] == 1:\n",
    "#         y_pred = np.array([[1 - y[0], y[0]] for y in y_pred])\n",
    "#         if y_true is not None:\n",
    "#             y_true = np.array([[1,0] if y == 0 else [0,1] for y in y_true.reshape(-1)])\n",
    "\n",
    "#     # make y_pred/y_true become one-hot prediction result\n",
    "#     # eg. y_true: [[1, 0, 0], [0, 0, 1], [0, 1, 0]] -> [0, 2, 1]\n",
    "#     # eg. y_pred: [[0.2, 0.41, 0.39], [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]] -> [1, 1, 2]\n",
    "#     if y_true is not None:\n",
    "#         y_true = np.argmax(y_true, axis=1)\n",
    "#     y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#     if y_true is not None:\n",
    "#         # compute accuracy\n",
    "#         correct = 0\n",
    "#         for yt, yp in zip(y_true, y_pred):\n",
    "#             if yt == yp:\n",
    "#                 correct += 1\n",
    "#         print(f\"Accuracy: {correct/n * 100:.2f}%\")\n",
    "\n",
    "#         # f1_scores = f1_score(y_true, y_pred, average=None)\n",
    "#         # print(f'f1 score for each class: {f1_scores}')\n",
    "#         # print(f'f1_macro score: {np.mean(np.array(f1_scores)):.2f}')\n",
    "#         MAPE = calculate_MAPE(y_pred, y_true)\n",
    "#         print(f\"MAPE: {MAPE}\")\n",
    "\n",
    "#     return y_pred\n",
    "\n",
    "def save_prediction_data(predicted_y):\n",
    "    # Create DataFrame with ID, x, and y columns\n",
    "    df = pd.DataFrame({\n",
    "        'ID': range(len(predicted_y)),  # Add ID column starting from 0\n",
    "        'y': predicted_y\n",
    "    })\n",
    "\n",
    "    # Ensure ID is the first column\n",
    "    df = df[['ID', 'y']]\n",
    "\n",
    "    # Save to CSV file\n",
    "    df.to_csv('Lab4_basic_regression.csv', index=False)\n",
    "    print(\"Prediction data saved as 'Lab4_basic_regression.csv'\")\n",
    "\n",
    "def animate_training(history, X_train, Y_train):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 11)\n",
    "    ax.set_ylim(-5, 5)\n",
    "    line, = ax.plot([], [], 'b-', lw=1, label='Predicted')\n",
    "\n",
    "    ground_truth_x = X_train.flatten()\n",
    "    ground_truth_y = Y_train.flatten()\n",
    "    ax.plot(ground_truth_x, ground_truth_y, 'r-', lw=1, label='Ground Truth')\n",
    "\n",
    "    # show current epoch on the animation / 100 epoch\n",
    "    epoch_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        epoch_text.set_text('')\n",
    "        return line, epoch_text\n",
    "\n",
    "    def update(frame):\n",
    "        epoch = (frame + 1) * 100\n",
    "        _, predicted_y = history[frame]\n",
    "        predicted_x = X_train.flatten()\n",
    "        line.set_data(predicted_x, predicted_y.flatten())\n",
    "\n",
    "        epoch_text.set_text(f'Epoch: {epoch}')\n",
    "\n",
    "        return line, epoch_text\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(history), init_func=init, blit=True, interval=50)\n",
    "\n",
    "    # save as gif\n",
    "    ani.save('Lab4_basic_regression.gif', writer='pillow')\n",
    "    plt.close(fig)\n",
    "    print(f\"Animation saved as 'Lab4_basic_regression.gif'\")\n",
    "\n",
    "\n",
    "def save_final_result(model, X_train, Y_train):\n",
    "    AL = model.forward(X_train)\n",
    "\n",
    "    predicted_x = X_train.flatten()\n",
    "    predicted_y = AL.flatten()\n",
    "\n",
    "    plt.plot(predicted_x, predicted_y, 'b-', label=\"Predicted\", lw=1)\n",
    "\n",
    "    ground_truth_x = X_train.flatten()\n",
    "    ground_truth_y = Y_train.flatten()\n",
    "\n",
    "    save_prediction_data(predicted_y)\n",
    "\n",
    "    plt.plot(ground_truth_x, ground_truth_y, 'r-', label='Ground Truth', lw=1)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.xlim(0, 11)\n",
    "    plt.savefig(\"Lab4_basic_regression.jpg\")\n",
    "    plt.show()\n",
    "    print(\"Prediction saved as 'Lab4_basic_regression.jpg'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1731235868764,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "fjOBHI0bGVE7"
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (n, f^{0})\n",
    "    Y -- true \"label\" vector, of shape (n, C)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    # permutation = list(np.random.permutation(m))\n",
    "    # shuffled_X = X[permutation, :]\n",
    "    # shuffled_Y = Y[permutation, :]\n",
    "\n",
    "    permutation = np.random.permutation(m)\n",
    "    shuffled_X = X[permutation]\n",
    "    shuffled_Y = Y[permutation]\n",
    "\n",
    "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
    "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        # mini_batch_X = shuffled_X[k * mini_batch_size : m - 1]\n",
    "        # mini_batch_Y = shuffled_Y[k * mini_batch_size : m - 1]\n",
    "        # mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        # mini_batches.append(mini_batch)\n",
    "\n",
    "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return mini_batches\n",
    "\n",
    "def train_model(model, X_train, Y_train, learning_rate, num_iterations, batch_size=None, print_loss=True, print_freq=1000, decrease_freq=100, decrease_proportion=0.99):\n",
    "    \"\"\"\n",
    "    Trains the model using mini-batch gradient descent\n",
    "\n",
    "    Arguments:\n",
    "    model -- the model to be trained\n",
    "    X_train -- training set, of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels, of shape (1, m_train)\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    batch_size -- size of a mini batch\n",
    "    print_loss -- if True, print the loss every print_freq iterations\n",
    "    print_freq -- print frequency\n",
    "    decrease_freq -- learning rate decrease frequency\n",
    "    decrease_proportion -- learning rate decrease proportion\n",
    "\n",
    "    Returns:\n",
    "    model -- the trained model\n",
    "    losses -- list of losses computed during the optimization\n",
    "    history -- list of (X_train, Y_pred) tuples for visualization\n",
    "    \"\"\"\n",
    "\n",
    "    history = []\n",
    "    losses = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        ### START CODE HERE ###\n",
    "        # Define mini batches\n",
    "        mini_batches = [(X_train, Y_train)]\n",
    "        if batch_size:\n",
    "            mini_batches = random_mini_batches(X_train, Y_train, batch_size)\n",
    "        else:\n",
    "            # if batch_size is None, batch is not used, mini_batch = whole dataset\n",
    "            mini_batches = [(X_train, Y_train)]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for batch in mini_batches:\n",
    "            X_batch, Y_batch = batch\n",
    "\n",
    "            # Forward pass\n",
    "            AL = model.forward(X_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            # if model.loss_function == 'cross_entropy':\n",
    "            #     if model.activation_functions[-1] == \"sigmoid\": # Binary classification\n",
    "            #         loss = compute_BCE_loss(AL, Y_batch)\n",
    "            #     elif model.activation_functions[-1] == \"softmax\": # Multi-class classification\n",
    "            #         loss = compute_CCE_loss(AL, Y_batch)\n",
    "            # elif model.loss_function == 'mse': # Regression\n",
    "            #     loss = compute_MSE_loss(AL, Y_batch)\n",
    "            loss = compute_MSE_loss(AL, Y_batch)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            # Backward pass\n",
    "            model.backward(AL, Y_batch)\n",
    "\n",
    "            # Update parameters\n",
    "            model.update(learning_rate)\n",
    "\n",
    "        epoch_loss /= len(mini_batches)\n",
    "        losses.append(epoch_loss)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Print loss\n",
    "        if print_loss and i % print_freq == 0:\n",
    "            print(f\"Loss after iteration {i}: {epoch_loss}\")\n",
    "\n",
    "        # Store history\n",
    "        if i % 100 == 0:\n",
    "            history.append((X_train, model.forward(X_train)))\n",
    "\n",
    "        # Decrease learning rate\n",
    "        if i % decrease_freq == 0 and i > 0:\n",
    "            learning_rate *= decrease_proportion\n",
    "\n",
    "    return model, losses, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessor(text):\n",
    "#     # remove HTML tags\n",
    "#     text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "#     # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "#     r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "#     emoticons = re.findall(r, text)\n",
    "#     text = re.sub(r, '', text)\n",
    "\n",
    "#     # convert to lowercase and append all emoticons behind (with space in between)\n",
    "#     # replace('-','') removes nose of emoticons\n",
    "#     text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "#     return text\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# stop = stopwords.words('english')\n",
    "\n",
    "# def tokenizer_stem_nostop(text):\n",
    "#     porter = PorterStemmer()\n",
    "#     return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "#             if w not in stop and re.match('[a-zA-Z]+', w)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessed(x, y):\n",
    "    y = y[:, np.newaxis]\n",
    "    combined = np.hstack((x, y))\n",
    "    nan_removed = combined[~np.isnan(combined).any(axis=1)]\n",
    "    x_train = nan_removed[:, :-1]\n",
    "    y_train = nan_removed[:, -1:]\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    y_train = scaler.fit_transform(y_train)\n",
    "    x_train[:, 0] = np.where(x_train[:, 0] > 0, np.log10(x_train[:, 0].clip(min=1e-10)), x_train[:, 0])\n",
    "    x_train[:, 1] = np.where(x_train[:, 1] > 0, np.log10(x_train[:, 1].clip(min=1e-10)), x_train[:, 1])\n",
    "    x_train[:, 2] = np.where(x_train[:, 2] > 0, np.log10(x_train[:, 2].clip(min=1e-10)), x_train[:, 2])\n",
    "    y_train[:, 0] = np.where(y_train[:, 0] > 0, np.log10(y_train[:, 0].clip(min=1e-10)), y_train[:, 0])\n",
    "    # x_train = (x_train - np.mean(x_train, axis=0)) / np.std(x_train, axis=0)\n",
    "    # y_train = (y_train - np.mean(y_train)) / np.std(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_train, Y_train, split_ratio=0.2):\n",
    "\n",
    "    x_split_size = int(len(X_train) * split_ratio)\n",
    "    y_split_size = int(len(Y_train) * split_ratio)\n",
    "    x_train = X_train[x_split_size:]\n",
    "    y_train = Y_train[y_split_size:]\n",
    "    x_val = X_train[:x_split_size]\n",
    "    y_val = Y_train[:y_split_size]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "data_root = \"out.csv\"\n",
    "with open(data_root, newline='') as csvfile:\n",
    "    datalist = pd.read_csv(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = CountVectorizer(ngram_range=(1, 1),\n",
    "#                         preprocessor=preprocessor,\n",
    "#                         tokenizer=tokenizer_stem_nostop)\n",
    "# datal = datalist.to_numpy()\n",
    "# count.fit(datal[:,7])\n",
    "# BoW = count.vocabulary_\n",
    "# print('[vocabulary]\\n{}'.format(BoW))\n",
    "# doc_bag = count.transform(datal[:,7])\n",
    "# doc_bag = doc_bag.toarray()\n",
    "# print(doc_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "error",
     "timestamp": 1731045408147,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "alsJ4F6eHZ2a",
    "outputId": "fba35e56-d600-47a9-981d-15fa7aa36964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1585, 3), y_train shape: (1585, 1)\n",
      "x_val shape: (396, 3), y_val shape: (396, 1)\n",
      "Loss after iteration 0: 0.007475833864810935\n",
      "Loss after iteration 1000: 0.003411428869782586\n",
      "Loss after iteration 2000: 0.0026174763317550515\n",
      "Loss after iteration 3000: 0.0023224122785730408\n",
      "Loss after iteration 4000: 0.0022501750504314347\n",
      "Loss after iteration 5000: 0.001930355755548002\n",
      "Loss after iteration 6000: 0.0017258647340779257\n",
      "Loss after iteration 7000: 0.0015727958395291334\n",
      "Loss after iteration 8000: 0.0014161659373750923\n",
      "Loss after iteration 9000: 0.0013272729811390901\n",
      "Loss after iteration 10000: 0.0012516631985159943\n",
      "Loss after iteration 11000: 0.0010960760346552536\n",
      "Loss after iteration 12000: 0.0010731016869546751\n",
      "Loss after iteration 13000: 0.0010305310076017852\n",
      "Loss after iteration 14000: 0.0010032412665359521\n",
      "Loss after iteration 15000: 0.0009802003471382607\n",
      "Loss after iteration 16000: 0.0009590710349774613\n",
      "Loss after iteration 17000: 0.0009455071093311279\n",
      "Loss after iteration 18000: 0.0009251986865018545\n",
      "Loss after iteration 19000: 0.0009191533039049978\n",
      "Loss after iteration 20000: 0.0009045428995903366\n",
      "Loss after iteration 21000: 0.0009010925515813505\n",
      "Loss after iteration 22000: 0.0008808593857065672\n",
      "Loss after iteration 23000: 0.0008865763911899249\n",
      "Loss after iteration 24000: 0.0008863133304484858\n",
      "Loss after iteration 25000: 0.0008816971239718319\n",
      "Loss after iteration 26000: 0.0008744827060320046\n",
      "Loss after iteration 27000: 0.0008701276480416603\n",
      "Loss after iteration 28000: 0.0008660564417112484\n",
      "Loss after iteration 29000: 0.0008653587918310935\n",
      "Loss after iteration 30000: 0.0008598869220022952\n",
      "Loss after iteration 31000: 0.0008589767948003202\n",
      "Loss after iteration 32000: 0.0008584791553402627\n",
      "Loss after iteration 33000: 0.0008552006376034086\n",
      "Loss after iteration 34000: 0.0008544592418945137\n",
      "Loss after iteration 35000: 0.000853487984736459\n",
      "Loss after iteration 36000: 0.0008511739633929228\n",
      "Loss after iteration 37000: 0.0008508661713814532\n",
      "Loss after iteration 38000: 0.0008506525853720819\n",
      "Loss after iteration 39000: 0.0008485560464252468\n",
      "Loss after iteration 40000: 0.0008484773498662801\n",
      "Loss after iteration 41000: 0.0008476262292469315\n",
      "Loss after iteration 42000: 0.0008461870481616727\n",
      "Loss after iteration 43000: 0.0008447860303627355\n",
      "Loss after iteration 44000: 0.0008456817545452877\n",
      "Loss after iteration 45000: 0.0008447743070838406\n",
      "Loss after iteration 46000: 0.0008438912512174862\n",
      "Loss after iteration 47000: 0.000845732697233715\n",
      "Loss after iteration 48000: 0.0008429525356920986\n",
      "Loss after iteration 49000: 0.0008445024305410548\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtered_data = datalist[(datalist[\"followers\"] > 10000) & (datalist[\"followers\"] < 1000000)]\n",
    "# data_isVideo = filtered_data[filtered_data[\"is Photo\"] == 0]\n",
    "data_isVideo = datalist[(datalist[\"followers\"] > 10) & (datalist[\"followers\"] < 10000) & (datalist[\"is Video\"] == 1)]\n",
    "# xy = filtered_data[[ \"followers\",\"is Photo\", \"hashtag_count\", \"days_diff\", \"Like Count\"]].to_numpy()\n",
    "xy_isVideo = data_isVideo[[ \"followers\", \"hashtag_count\", \"days_diff\", \"Like Count\"]].to_numpy()\n",
    "\n",
    "x_isVideo = xy_isVideo[:, :-1]  \n",
    "y_isVideo = xy_isVideo[:, -1]   \n",
    "x_processed_isVideo, y_processed_isVideo = preProcessed(x_isVideo, y_isVideo)\n",
    "x_train_isVideo, y_train_isVideo, x_val_isVideo, y_val_isVideo = split_data(x_processed_isVideo, y_processed_isVideo, split_ratio=0.2)\n",
    "print(f\"x_train shape: {x_train_isVideo.shape}, y_train shape: {y_train_isVideo.shape}\")\n",
    "print(f\"x_val shape: {x_val_isVideo.shape}, y_val shape: {y_val_isVideo.shape}\")\n",
    "\n",
    "loss_function = \"mse\";\n",
    "layers_dims = [x_train_isVideo.shape[-1], 32, 16, 1] # linear for converge, sigmoid for diverge\n",
    "activation_fn = [\"relu\", \"relu\", \"linear\"]\n",
    "learning_rate = 0.05\n",
    "num_iterations = 50000\n",
    "print_loss = True\n",
    "print_freq = 1000\n",
    "decrease_freq = 1000\n",
    "decrease_proportion = 0.9\n",
    "batch_size = 16 \n",
    "\n",
    "model_isVideo = Model(layers_dims, activation_fn, loss_function)\n",
    "model_isVideo, losses, history = train_model(model_isVideo, x_train_isVideo, y_train_isVideo, learning_rate, num_iterations, batch_size, print_loss, print_freq, decrease_freq, decrease_proportion)\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training Loss (Initial LR: {learning_rate})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1572, 3), y_train shape: (1572, 1)\n",
      "x_val shape: (392, 3), y_val shape: (392, 1)\n",
      "Loss after iteration 0: 0.0022333453759689264\n",
      "Loss after iteration 1000: 2.760586949373095e-06\n",
      "Loss after iteration 2000: 1.6100113947689027e-06\n",
      "Loss after iteration 3000: 1.206897926083247e-06\n",
      "Loss after iteration 4000: 1.0164726434786984e-06\n",
      "Loss after iteration 5000: 9.178785094729081e-07\n",
      "Loss after iteration 6000: 8.475100393446006e-07\n",
      "Loss after iteration 7000: 7.909645092048214e-07\n",
      "Loss after iteration 8000: 7.461022574266681e-07\n",
      "Loss after iteration 9000: 6.394855195252002e-07\n",
      "Loss after iteration 10000: 5.705816621665087e-07\n",
      "Loss after iteration 11000: 5.401520138751693e-07\n",
      "Loss after iteration 12000: 5.204887463168097e-07\n",
      "Loss after iteration 13000: 5.027685209162537e-07\n",
      "Loss after iteration 14000: 4.920292041420676e-07\n",
      "Loss after iteration 15000: 4.843582243034365e-07\n",
      "Loss after iteration 16000: 4.741394446317862e-07\n",
      "Loss after iteration 17000: 4.6582272376921344e-07\n",
      "Loss after iteration 18000: 4.861218320290742e-07\n",
      "Loss after iteration 19000: 4.665236722331963e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_isPhoto = filtered_data[filtered_data[\"is Photo\"] == 1]\n",
    "data_isPhoto = datalist[(datalist[\"followers\"] > 10000) & (datalist[\"followers\"] < 1000000) & (datalist[\"is Photo\"] == 1)]\n",
    "xy_isPhoto = data_isPhoto[[ \"followers\", \"hashtag_count\", \"days_diff\", \"Like Count\"]].to_numpy()\n",
    "\n",
    "x_isPhoto = xy_isPhoto[:, :-1]  \n",
    "y_isPhoto = xy_isPhoto[:, -1]   \n",
    "x_processed_isPhoto, y_processed_isPhoto = preProcessed(x_isPhoto, y_isPhoto)\n",
    "x_train_isPhoto, y_train_isPhoto, x_val_isPhoto, y_val_isPhoto = split_data(x_processed_isPhoto, y_processed_isPhoto, split_ratio=0.2)\n",
    "print(f\"x_train shape: {x_train_isPhoto.shape}, y_train shape: {y_train_isPhoto.shape}\")\n",
    "print(f\"x_val shape: {x_val_isPhoto.shape}, y_val shape: {y_val_isPhoto.shape}\")\n",
    "\n",
    "loss_function = \"mse\";\n",
    "layers_dims = [x_train_isPhoto.shape[-1], 32, 16, 1] # linear for converge, sigmoid for diverge\n",
    "activation_fn = [\"relu\", \"relu\", \"linear\"]\n",
    "learning_rate = 0.05\n",
    "num_iterations = 20000\n",
    "print_loss = True\n",
    "print_freq = 1000\n",
    "decrease_freq = 1000\n",
    "decrease_proportion = 0.9\n",
    "batch_size = 16 \n",
    "\n",
    "model_isPhoto = Model(layers_dims, activation_fn, loss_function)\n",
    "model_isPhoto, losses, history = train_model(model_isPhoto, x_train_isPhoto, y_train_isPhoto, learning_rate, num_iterations, batch_size, print_loss, print_freq, decrease_freq, decrease_proportion)\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training Loss (Initial LR: {learning_rate})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAPE(prediction, ground_truth):\n",
    "    ground_truth = np.where(ground_truth == 0, np.finfo(float).eps, ground_truth) # ensure no 0 in nparray\n",
    "    mape = np.sum(np.abs((ground_truth - prediction) / ground_truth)) / len(prediction) * 100\n",
    "    return mape\n",
    "\n",
    "def predict(x, y_true, model):\n",
    "    # 預測\n",
    "    y_pred = model.forward(x)\n",
    "    \n",
    "    if y_true is not None:\n",
    "        # Mean Squared Error\n",
    "        mse = np.mean(np.square(y_pred - y_true))\n",
    "        print(f\"MSE : {mse}\")\n",
    "\n",
    "        # Mean Absolute Error\n",
    "        mae = np.mean(np.abs(y_pred - y_true))\n",
    "        print(f\"MAE : {mae}\")\n",
    "\n",
    "        mape = calculate_MAPE(y_true, y_pred)\n",
    "        print(f\"MAPE {mape:.2f}%\")\n",
    "\n",
    "        # Accuracy (within tolerance)\n",
    "        # tolerance = 1e-3 \n",
    "        # correct = np.sum(np.isclose(y_pred.flatten(), y_true.flatten(), atol=tolerance))\n",
    "        # accuracy = correct / len(y_true) * 100\n",
    "        # print(f\"Accuracy (within tolerance of {tolerance}): {accuracy:.2f}%\")\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load validation data\n",
    "# data_val_root = \"out.csv\"\n",
    "# with open(data_val_root, newline='') as csvfile:\n",
    "#     datalist_val = pd.read_csv(data_val_root)\n",
    "\n",
    "# filtered_data_val = datalist_val[(datalist_val[\"followers\"] > 10000) & (datalist_val[\"followers\"] < 1000000)]\n",
    "# data_val_isVideo = filtered_data_val[filtered_data_val[\"is Photo\"] == 0]\n",
    "# xy_val_isVideo = data_val_isVideo[[ \"followers\", \"hashtag_count\", \"days_diff\", \"Like Count\"]].to_numpy()\n",
    "\n",
    "# x_val_isVideo = xy_val_isVideo[:, :-1]  \n",
    "# y_val_isVideo = xy_val_isVideo[:, -1]   \n",
    "# x_val_processed_isVideo, y_processed_isVideo = preProcessed(x_isVideo, y_isVideo)\n",
    "\n",
    "# data_val_isPhoto = filtered_data_val[filtered_data_val[\"is Photo\"] == 1]\n",
    "# xy_val_isPhoto = data_val_isPhoto[[ \"followers\", \"hashtag_count\", \"days_diff\", \"Like Count\"]].to_numpy()\n",
    "\n",
    "# x_val_isPhoto = xy_val_isPhoto[:, :-1]  \n",
    "# y_val_isPhoto = xy_val_isPhoto[:, -1]   \n",
    "# x_val_processed_isPhoto, y_processed_isPhoto = preProcessed(x_isPhoto, y_isPhoto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 18966,
     "status": "ok",
     "timestamp": 1730912432655,
     "user": {
      "displayName": "賴詠欣",
      "userId": "11548507785211494753"
     },
     "user_tz": -480
    },
    "id": "0uwle3uqL9Em",
    "outputId": "d753b672-494a-4d1b-a6a0-bd1f99ae0f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photo post predict:\n",
      "training data\n",
      "MSE : 4.5372990877749997e-07\n",
      "MAE : 0.0003792644961862779\n",
      "MAPE 1.68%\n",
      "validation data\n",
      "MSE : 0.007113541377323384\n",
      "MAE : 0.0050181057407585935\n",
      "MAPE 21.89%\n",
      "video post predict:\n",
      "training data\n",
      "MSE : 0.0008496013252137939\n",
      "MAE : 0.004335430942835059\n",
      "MAPE 21.93%\n",
      "validation data\n",
      "MSE : 0.07477262665232576\n",
      "MAE : 0.12460782748875279\n",
      "MAPE 57.39%\n"
     ]
    }
   ],
   "source": [
    "print(\"photo post predict:\")\n",
    "print(\"training data\")\n",
    "pred_train = predict(x_train_isPhoto, y_train_isPhoto, model_isPhoto)\n",
    "print(\"validation data\")\n",
    "pred_val = predict(x_val_isPhoto, y_val_isPhoto, model_isPhoto)\n",
    "print(\"video post predict:\")\n",
    "print(\"training data\")\n",
    "pred_train = predict(x_train_isVideo, y_train_isVideo, model_isVideo)\n",
    "print(\"validation data\")\n",
    "pred_val = predict(x_val_isVideo, y_val_isVideo, model_isVideo)\n",
    "# save_final_result(model, x_train, y_train)\n",
    "# animate_training(history, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction data saved as 'training_output.csv'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ID': range(len(pred_train)),\n",
    "    'Label': pred_train.flatten()\n",
    "})\n",
    "\n",
    "df.to_csv('training_output.csv', index=False)\n",
    "print(\"Prediction data saved as 'training_output.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
